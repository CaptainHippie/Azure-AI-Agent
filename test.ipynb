{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccb9005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9f75ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My_Resume_Final_v2.pdf'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from werkzeug.utils import secure_filename\n",
    "\n",
    "secure_filename(\"My R√©sum√© (Final) v2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f916ccac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ed3d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.rag import Return_Poller_Result, embeddings_deployment, openai_client, search_client\n",
    "import base64\n",
    "\n",
    "file_url = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "015727c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Return_Poller_Result(file_url)\n",
    "markdown_text = result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1812b24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f047f18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['apiVersion', 'modelId', 'stringIndexType', 'content', 'pages', 'paragraphs', 'styles', 'contentFormat', 'sections'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.as_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ddb6043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_client.get_document_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17a0d3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chonkie import RecursiveChunker\n",
    "\n",
    "chunker = RecursiveChunker(\n",
    "    chunk_size=512,\n",
    "    min_characters_per_chunk=100,\n",
    ")\n",
    "chunks = chunker.chunk(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00bf87c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_client.embeddings.create(\n",
    "            input=[chunk.text for chunk in chunks],\n",
    "            model=embeddings_deployment\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "572cf8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a54c5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Django_skills_section.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876667ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_documents = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f78ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_documents = [{\n",
    "    \"id\": base64.urlsafe_b64encode(f\"{filename}_{i + 1}\".encode()).decode(),\n",
    "    \"content\": chunk.text,\n",
    "    \"text_vector\": response.data[i].embedding,\n",
    "    \"chunk_index\": i + 1,\n",
    "    \"source_url\": file_url,\n",
    "    \"source_document\": filename\n",
    "} for i, chunk in enumerate(chunks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb2368e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 22 chunks to Azure AI Search.\n"
     ]
    }
   ],
   "source": [
    "# E. Upload to Azure AI Search\n",
    "if search_documents:\n",
    "    search_client.upload_documents(documents=search_documents)\n",
    "    print(f\"Uploaded {len(search_documents)} chunks to Azure AI Search.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c806b517",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Generate embedding for the query\n",
    "    embedding_response = openai_client.embeddings.create(\n",
    "        input=query,\n",
    "        model=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n",
    "    )\n",
    "    query_vector = embedding_response.data[0].embedding\n",
    "\n",
    "    # Create Filter string (OData format)\n",
    "    filter_str = None\n",
    "    if filename_filter:\n",
    "        filter_str = f\"source eq '{filename_filter}'\"\n",
    "\n",
    "    # Search Azure AI Search\n",
    "    results = search_client.search(\n",
    "        search_text=query,\n",
    "        vector_queries=[VectorizedQuery(vector=query_vector, k_nearest_neighbors=3, fields=\"vector\")],\n",
    "        filter=filter_str,\n",
    "        select=[\"content\", \"source\"]\n",
    "    )\n",
    "\n",
    "    # Format results for the LLM\n",
    "    context = []\n",
    "    sources = set()\n",
    "    for res in results:\n",
    "        context.append(res['content'])\n",
    "        sources.add(res['source'])\n",
    "        \n",
    "    return json.dumps({\"context\": \"\\n\\n\".join(context), \"sources\": list(sources)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24c8d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.models import VectorizableTextQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "999efb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Django_skills_section.pdf'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4bb1b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"hihi\"\n",
    "count = 5\n",
    "vector_query = VectorizableTextQuery(text=query_text, fields=\"text_vector\")\n",
    "search_query = search_client.search(\n",
    "        search_text=query_text,  # Keyword search\n",
    "        vector_queries=[vector_query],  # Vector search\n",
    "        top=count,  # Limit results\n",
    "        #filter=f\"source_document eq '{filename}'\",  # Filtering\n",
    "        query_type=\"simple\",\n",
    "        search_fields=[\"content\"],  # Fields to search\n",
    "        select=['content', 'source_url', 'source_document', 'chunk_index']\n",
    "    )\n",
    "\n",
    "query_documents = [{k: v for k, v in doc.items() if not k.startswith(\"@\")} for doc in search_query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "24184279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source_url': 'https://buddiz.blob.core.windows.net/test-rag-container/lesson.pdf',\n",
       "  'source_document': 'lesson.pdf',\n",
       "  'chunk_index': 15,\n",
       "  'content': 'capability managers love.\\n\\n\\n# Part 4: The Final Presentation (Synthesis)\\n\\nHere is the answer key for the final recommendation based on the provided dataset logic.\\n\\n\\n## Analysis of the Data:\\n\\n1\\\\. Best Sector: If you look at the Heatmap, AI has the darkest squares (highest growth) across most\\nregions, but FinTech usually has the best balance of Revenue stability. However, strictly for\\n\"Risk/Growth Balance,\" SaaS often shows up as moderate risk (3-5) with consistent growth. Let\\'s\\n'},\n",
       " {'source_url': 'https://buddiz.blob.core.windows.net/test-rag-container/Django_skills_section.pdf',\n",
       "  'source_document': 'Django_skills_section.pdf',\n",
       "  'chunk_index': 1,\n",
       "  'content': 'This is a great teaching scenario. It perfectly illustrates the difference between Data Entry Ease (Method 1) vs. Data Integrity & Normalization (Method 2).\\n\\nHere is the lesson plan, broken down into the two approaches, with detailed explanations on the Admin configuration as requested.\\n\\n\\n# Introduction for the Student\\n\\n\"Today we are building a user profile. We need to store their skills (like \\'Figma\\' or \\'Python\\') and how good they are at it (0-100%). We are going to try two ways to do\\n'},\n",
       " {'source_url': 'https://buddiz.blob.core.windows.net/test-rag-container/lesson.pdf',\n",
       "  'source_document': 'lesson.pdf',\n",
       "  'chunk_index': 9,\n",
       "  'content': 'xytext=(nebula [\\'Risk_Score\\' ]-1. 5, nebula [ \\'Valuation_B\\' ] +2) ,\\narrowprops=dict (facecolor=\\'black\\', shrink=0.05)\\n)\\n\\n\\\\# Reference Line\\nax1. axhline (y=10, color=\\'grey\\', linestyle=\\' -- \\', alpha=0.5)\\nax1. text (x=1, y=10.5, s=\"Unicorn Threshold (10B) \", color=\\'grey\\')\\n\\n¬∑ Common Mistake: Forgetting sizes= (min, max) . Without this, the bubbles might be too\\nsmall to see differences.\\n\\n¬∑ Detour: Ask the student to change the hue to Region to see if Risk is geographically\\nclustered.\\n\\n'},\n",
       " {'source_url': 'https://buddiz.blob.core.windows.net/test-rag-container/lesson.pdf',\n",
       "  'source_document': 'lesson.pdf',\n",
       "  'chunk_index': 11,\n",
       "  'content': 'Teaching Note: We will use the manual hlines method. It is harder but produces a much more\\nprofessional \"Data Journalism\" look than a standard bar chart.\\n\\n\\n## Correct Code:\\n\\n\\\\# Data Prep\\ntop_growth = df . sort_values ( \\' Growth_Pct\\', ascending=True) . tail (10) # Asce\\n\\n\\\\# Plot Sticks\\nax3. hlines (\\ny=top_growth [ \\' Name \\' ] ,\\nxmin=0,\\nxmax=top_growth [ \\' Growth_Pct\\' ] ,\\ncolor=\\' skyblue\\',\\nlinewidth=3\\n)\\n\\n\\\\# Plot Heads (Dots)\\nax3.plot (\\ntop_growth [ \\' Growth_Pct\\' ],\\n\\n<!-- PageBreak -->\\n'},\n",
       " {'source_url': 'https://buddiz.blob.core.windows.net/test-rag-container/lesson.pdf',\n",
       "  'source_document': 'lesson.pdf',\n",
       "  'chunk_index': 16,\n",
       "  'content': 'check the code outputs.\\n\\n2\\\\. Safe Bet: From Part 1.3 , the filter Risk < 5, Growth > 30 usually catches\\n\"AlphaQuant\" or \"CodeBase\".\\n\\n3\\\\. Moonshot: From the 3D plot, \"NebulaAI\" is the clear winner (High Val, High Growth, High Risk).\\n\\n\\n### Correct Output String Code:\\n\\nprint (\"-\" * 30)\\nprint (\"EXECUTIVE SUMMARY: APEX VENTURES\")\\nprint (\"-\" * 30)\\n\\nprint (\"1. SECTOR STRATEGY: Invest in ** AI ** for pure growth, but ** FinTec\\nprint (\"2. THE SAFE BET: ** AlphaQuant ** (FinTech) . Low Risk (5), Healthy C\\n'}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "838e48ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source_url': 'https://buddiz.blob.core.windows.net/test-rag-container/lesson.pdf',\n",
       " 'source_document': 'lesson.pdf',\n",
       " 'chunk_index': 15,\n",
       " 'content': 'capability managers love.\\n\\n\\n# Part 4: The Final Presentation (Synthesis)\\n\\nHere is the answer key for the final recommendation based on the provided dataset logic.\\n\\n\\n## Analysis of the Data:\\n\\n1\\\\. Best Sector: If you look at the Heatmap, AI has the darkest squares (highest growth) across most\\nregions, but FinTech usually has the best balance of Revenue stability. However, strictly for\\n\"Risk/Growth Balance,\" SaaS often shows up as moderate risk (3-5) with consistent growth. Let\\'s\\n',\n",
       " '@search.score': 0.01666666753590107,\n",
       " '@search.reranker_score': None,\n",
       " '@search.highlights': None,\n",
       " '@search.captions': None}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad95520a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lesson.pdf': {'context': ['capability managers love.\\n\\n\\n# Part 4: The Final Presentation (Synthesis)\\n\\nHere is the answer key for the final recommendation based on the provided dataset logic.\\n\\n\\n## Analysis of the Data:\\n\\n1\\\\. Best Sector: If you look at the Heatmap, AI has the darkest squares (highest growth) across most\\nregions, but FinTech usually has the best balance of Revenue stability. However, strictly for\\n\"Risk/Growth Balance,\" SaaS often shows up as moderate risk (3-5) with consistent growth. Let\\'s\\n',\n",
       "   'xytext=(nebula [\\'Risk_Score\\' ]-1. 5, nebula [ \\'Valuation_B\\' ] +2) ,\\narrowprops=dict (facecolor=\\'black\\', shrink=0.05)\\n)\\n\\n\\\\# Reference Line\\nax1. axhline (y=10, color=\\'grey\\', linestyle=\\' -- \\', alpha=0.5)\\nax1. text (x=1, y=10.5, s=\"Unicorn Threshold (10B) \", color=\\'grey\\')\\n\\n¬∑ Common Mistake: Forgetting sizes= (min, max) . Without this, the bubbles might be too\\nsmall to see differences.\\n\\n¬∑ Detour: Ask the student to change the hue to Region to see if Risk is geographically\\nclustered.\\n\\n',\n",
       "   'Teaching Note: We will use the manual hlines method. It is harder but produces a much more\\nprofessional \"Data Journalism\" look than a standard bar chart.\\n\\n\\n## Correct Code:\\n\\n\\\\# Data Prep\\ntop_growth = df . sort_values ( \\' Growth_Pct\\', ascending=True) . tail (10) # Asce\\n\\n\\\\# Plot Sticks\\nax3. hlines (\\ny=top_growth [ \\' Name \\' ] ,\\nxmin=0,\\nxmax=top_growth [ \\' Growth_Pct\\' ] ,\\ncolor=\\' skyblue\\',\\nlinewidth=3\\n)\\n\\n\\\\# Plot Heads (Dots)\\nax3.plot (\\ntop_growth [ \\' Growth_Pct\\' ],\\n\\n<!-- PageBreak -->\\n',\n",
       "   'check the code outputs.\\n\\n2\\\\. Safe Bet: From Part 1.3 , the filter Risk < 5, Growth > 30 usually catches\\n\"AlphaQuant\" or \"CodeBase\".\\n\\n3\\\\. Moonshot: From the 3D plot, \"NebulaAI\" is the clear winner (High Val, High Growth, High Risk).\\n\\n\\n### Correct Output String Code:\\n\\nprint (\"-\" * 30)\\nprint (\"EXECUTIVE SUMMARY: APEX VENTURES\")\\nprint (\"-\" * 30)\\n\\nprint (\"1. SECTOR STRATEGY: Invest in ** AI ** for pure growth, but ** FinTec\\nprint (\"2. THE SAFE BET: ** AlphaQuant ** (FinTech) . Low Risk (5), Healthy C\\n'],\n",
       "  'url': 'https://buddiz.blob.core.windows.net/test-rag-container/lesson.pdf'},\n",
       " 'Django_skills_section.pdf': {'context': ['This is a great teaching scenario. It perfectly illustrates the difference between Data Entry Ease (Method 1) vs. Data Integrity & Normalization (Method 2).\\n\\nHere is the lesson plan, broken down into the two approaches, with detailed explanations on the Admin configuration as requested.\\n\\n\\n# Introduction for the Student\\n\\n\"Today we are building a user profile. We need to store their skills (like \\'Figma\\' or \\'Python\\') and how good they are at it (0-100%). We are going to try two ways to do\\n'],\n",
       "  'url': 'https://buddiz.blob.core.windows.net/test-rag-container/Django_skills_section.pdf'}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources = {}\n",
    "for document in query_documents:\n",
    "    if document['source_document'] in sources:\n",
    "        temp_list = {\"context\": []}\n",
    "        sources[document['source_document']]['context'].append(document['content'])\n",
    "    else:\n",
    "        sources[document['source_document']] = {\"url\": document['source_url'], \"context\": [document['content']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a04033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. The Tool Function (The actual RAG retrieval) ---\n",
    "def search_knowledge_base(query: str, filename: str = None, count: int = 5):\n",
    "    \"\"\"\n",
    "    Retreives relevant context chunks from the Azure AI Search index.\n",
    "    \"\"\"\n",
    "    print(f\"üõ†Ô∏è Tool Triggered: Searching for '{query}' in '{filename}'\")\n",
    "    vector_query = VectorizableTextQuery(text=query, fields=\"text_vector\")\n",
    "    search_query = search_client.search(\n",
    "            search_text=query,  # Keyword search\n",
    "            vector_queries=[vector_query],  # Vector search\n",
    "            top=count,  # Limit results\n",
    "            filter=f\"source_document eq '{filename}'\",  # Filtering\n",
    "            query_type=\"simple\",\n",
    "            search_fields=[\"content\"],  # Fields to search\n",
    "            select=['content', 'source_url', 'source_document', 'chunk_index']\n",
    "        )\n",
    "\n",
    "    query_documents = [{k: v for k, v in doc.items() if not k.startswith(\"@\")} for doc in search_query]\n",
    "\n",
    "    sources = {}\n",
    "    for document in query_documents:\n",
    "        if document['source_document'] in sources:\n",
    "            temp_list = {\"context\": []}\n",
    "            sources[document['source_document']]['context'].append(document['content'])\n",
    "        else:\n",
    "            sources[document['source_document']] = {\"url\": document['source_url'], \"context\": [document['content']]}\n",
    "\n",
    "    return sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59dd460",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/ask\", response_model=AskResponse)\n",
    "async def ask_question(request: AskRequest):\n",
    "    try:\n",
    "        # Pass the request data to the agent logic\n",
    "        answer, sources = run_agent(\n",
    "            user_query=request.query, \n",
    "            session_id=request.session_id,\n",
    "            target_file=request.target_file\n",
    "        )\n",
    "        \n",
    "        return AskResponse(\n",
    "            answer=answer,\n",
    "            source=sources\n",
    "        )\n",
    "    except Exception as e:\n",
    "        # Log error for debugging\n",
    "        print(f\"Error in /ask: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433993e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if selected_doc:\n",
    "    st.sidebar.success(f\"Active: {selected_doc}\")\n",
    "    # Pass 'selected_doc' to your chat API payload\n",
    "    # payload = { \"query\": prompt, \"filter_filename\": selected_doc }\n",
    "\n",
    "# 1. Upload New File\n",
    "uploaded_file = st.sidebar.file_uploader(\"Upload a PDF\", type=\"pdf\")\n",
    "if uploaded_file:\n",
    "    if st.sidebar.button(\"Process & Index\"):\n",
    "        with st.spinner(\"Uploading and Indexing...\"):\n",
    "            files = {\"file\": (uploaded_file.name, uploaded_file, \"application/pdf\")}\n",
    "            response = requests.post(f\"{API_URL}/upload\", files=files)\n",
    "            if response.status_code == 200:\n",
    "                st.sidebar.success(\"File Indexed!\")\n",
    "            else:\n",
    "                st.sidebar.error(\"Upload failed\")\n",
    "\n",
    "# 2. View Available Files\n",
    "st.sidebar.subheader(\"Current Documents\")\n",
    "try:\n",
    "    files_res = requests.get(f\"{API_URL}/files\")\n",
    "    files_list = files_res.json().get(\"files\", [])\n",
    "    st.sidebar.write(files_list)\n",
    "except:\n",
    "    st.sidebar.error(\"Backend not connected\")\n",
    "\n",
    "# --- Main Chat Interface ---\n",
    "\n",
    "# Initialize chat history in Streamlit session state\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# Display chat history\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "# User Input\n",
    "if prompt := st.chat_input(\"Ask a question...\"):\n",
    "    # 1. Display user message\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(prompt)\n",
    "\n",
    "    # 2. Send to FastAPI\n",
    "    # Prepare Payload\n",
    "    payload = {\n",
    "        \"query\": prompt,\n",
    "        \"session_id\": \"streamlit_user_1\", # Simple ID for now\n",
    "        \"target_file\": selected_doc if selected_doc else None\n",
    "    }\n",
    "\n",
    "    # Call FastAPI\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        try:\n",
    "            res = requests.post(f\"{API_URL}/ask\", json=payload)\n",
    "            data = res.json()\n",
    "            \n",
    "            answer = data[\"answer\"]\n",
    "            sources = data.get(\"source\", [])\n",
    "            \n",
    "            st.markdown(answer)\n",
    "            if sources:\n",
    "                st.caption(f\"üìö Sources: {', '.join(sources)}\")\n",
    "                \n",
    "            st.session_state.messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "            \n",
    "        except Exception as e:\n",
    "            st.error(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
